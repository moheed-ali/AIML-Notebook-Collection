{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO0iIXU190MQ1ZhKNXrQQ8K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Implementing MLPs with Keras**"],"metadata":{"id":"PAZSynyBXZPY"}},{"cell_type":"markdown","source":["# **1st Run**\n","*   **Layers:** Three hidden layers.\n","*   **Number of Neurons:** 50 neurons in each hidden layer.\n","*   **Activation Function:** Rectified Linear Unit (ReLU) activation function for each hidden layer. No activation function for the output layer (typical for regression tasks).\n","*   **Optimizer:** Adam optimizer.\n","*   **Learning Rate:** Learning rate is set to 0.001 for the Adam optimizer.\n","\n","**Result**\n","*   **RMSE:** 0.552616078251524\n","\n"],"metadata":{"id":"oLvqTQ0oWl_r"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BK8P-4CtV1wg","executionInfo":{"status":"ok","timestamp":1701517506114,"user_tz":-60,"elapsed":65399,"user":{"displayName":"Ali Kayani","userId":"06247636638040147084"}},"outputId":"88155b5f-2f6e-498b-ee34-3e7d2991a4d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","363/363 [==============================] - 4s 7ms/step - loss: 0.8425 - val_loss: 0.5125\n","Epoch 2/50\n","363/363 [==============================] - 2s 5ms/step - loss: 0.3819 - val_loss: 1.2632\n","Epoch 3/50\n","363/363 [==============================] - 2s 6ms/step - loss: 0.3619 - val_loss: 0.3732\n","Epoch 4/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.3390 - val_loss: 1.3246\n","Epoch 5/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.7133\n","Epoch 6/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3266 - val_loss: 0.3169\n","Epoch 7/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3124 - val_loss: 2.2594\n","Epoch 8/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.4211\n","Epoch 9/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.3063 - val_loss: 0.6285\n","Epoch 10/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.3027 - val_loss: 0.2972\n","Epoch 11/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 0.4422\n","Epoch 12/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2939 - val_loss: 0.2897\n","Epoch 13/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2870 - val_loss: 0.4011\n","Epoch 14/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.2888\n","Epoch 15/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2799 - val_loss: 0.4539\n","Epoch 16/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2755 - val_loss: 0.2755\n","Epoch 17/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2750 - val_loss: 0.3047\n","Epoch 18/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2692 - val_loss: 0.3082\n","Epoch 19/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2700 - val_loss: 0.3736\n","Epoch 20/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2711 - val_loss: 0.2774\n","Epoch 21/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2657 - val_loss: 0.2909\n","Epoch 22/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2618 - val_loss: 0.3018\n","Epoch 23/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2613 - val_loss: 0.3530\n","Epoch 24/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2628 - val_loss: 0.4143\n","Epoch 25/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2614 - val_loss: 0.4970\n","Epoch 26/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2579 - val_loss: 0.2907\n","Epoch 27/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2571 - val_loss: 0.3280\n","Epoch 28/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2521 - val_loss: 0.2802\n","Epoch 29/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2518 - val_loss: 0.2893\n","Epoch 30/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2494 - val_loss: 0.2628\n","Epoch 31/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2493 - val_loss: 0.2998\n","Epoch 32/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2491 - val_loss: 0.2928\n","Epoch 33/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2483 - val_loss: 0.2586\n","Epoch 34/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2453 - val_loss: 0.2882\n","Epoch 35/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2443 - val_loss: 0.2556\n","Epoch 36/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2404 - val_loss: 0.6018\n","Epoch 37/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2434 - val_loss: 0.2586\n","Epoch 38/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2388 - val_loss: 0.2711\n","Epoch 39/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2388 - val_loss: 0.3071\n","Epoch 40/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2380 - val_loss: 0.2555\n","Epoch 41/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2356 - val_loss: 0.4110\n","Epoch 42/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2364 - val_loss: 0.2539\n","Epoch 43/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2383 - val_loss: 0.3808\n","Epoch 44/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2339 - val_loss: 0.2713\n","Epoch 45/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2340 - val_loss: 0.3233\n","Epoch 46/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2320 - val_loss: 0.3082\n","Epoch 47/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2302 - val_loss: 0.2699\n","Epoch 48/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2286 - val_loss: 0.5980\n","Epoch 49/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2281 - val_loss: 0.3154\n","Epoch 50/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2289 - val_loss: 0.3054\n","121/121 [==============================] - 0s 1ms/step\n","0.552616078251524\n"]}],"source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import fetch_california_housing\n","\n","# Load the California housing dataset\n","housing = fetch_california_housing()\n","\n","# Split the dataset into training and testing sets\n","X_train_full, X_test, y_train_full, y_test = train_test_split(\n","    housing.data, housing.target, random_state=42)\n","\n","# Further split the training set into training and validation sets\n","X_train, X_valid, y_train, y_valid = train_test_split(\n","    X_train_full, y_train_full, random_state=42)\n","\n","# Standardize the features using StandardScaler\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_valid_scaled = scaler.transform(X_valid)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Create a Keras Sequential model\n","model = Sequential([\n","    Dense(50, activation='relu', input_shape=(X_train.shape[1],)),\n","    Dense(50, activation='relu'),\n","    Dense(50, activation='relu'),\n","    Dense(1)  # Output layer with a single neuron for regression\n","])\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n","\n","# Train the model on the training data\n","model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_valid_scaled, y_valid), verbose=1)\n","\n","# Make predictions on the validation set\n","y_pred = model.predict(X_valid_scaled).flatten()\n","\n","# Calculate the Root Mean Squared Error (RMSE) between the predicted and actual values\n","rmse = mean_squared_error(y_valid, y_pred, squared=False)\n","\n","# Display the RMSE as the result\n","print(rmse)\n"]},{"cell_type":"markdown","source":["# **2nd Run**\n","*   **Layers:** Three hidden layers.\n","*   **Number of Neurons:** 100 neurons in each hidden layer.\n","*   **Activation Function:** Rectified Linear Unit (ReLU) activation function for each hidden layer. No activation function for the output layer (typical for regression tasks).\n","*   **Optimizer:** SGD optimizer.\n","*   **Learning Rate:** Learning rate is set to 0.01 for the SGD optimizer.\n","\n","**Result**\n","*   **RMSE:** 0.5076683354576565\n",""],"metadata":{"id":"3gmvedGJX-Xn"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701518181187,"user_tz":-60,"elapsed":84037,"user":{"displayName":"Ali Kayani","userId":"06247636638040147084"}},"outputId":"e871db8d-3ef5-4ee1-b8aa-73904351ae8c","id":"eG7dYki3X-X6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","363/363 [==============================] - 2s 3ms/step - loss: 0.9422 - val_loss: 2.3921\n","Epoch 2/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 14.9470\n","Epoch 3/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.4151 - val_loss: 1.5050\n","Epoch 4/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.8104\n","Epoch 5/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.8598\n","Epoch 6/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.9540\n","Epoch 7/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3420 - val_loss: 1.6431\n","Epoch 8/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.7910\n","Epoch 9/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.4664\n","Epoch 10/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.4464\n","Epoch 11/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.3174 - val_loss: 0.3327\n","Epoch 12/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3109 - val_loss: 0.3971\n","Epoch 13/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3088 - val_loss: 0.3064\n","Epoch 14/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3046 - val_loss: 0.3234\n","Epoch 15/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.3013 - val_loss: 0.2937\n","Epoch 16/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2972 - val_loss: 0.3686\n","Epoch 17/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2955 - val_loss: 0.3599\n","Epoch 18/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2921 - val_loss: 0.3081\n","Epoch 19/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2896 - val_loss: 0.3143\n","Epoch 20/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2860 - val_loss: 0.2972\n","Epoch 21/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.2745\n","Epoch 22/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2809 - val_loss: 0.3092\n","Epoch 23/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2801 - val_loss: 0.3013\n","Epoch 24/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2794 - val_loss: 0.2742\n","Epoch 25/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2775 - val_loss: 0.2883\n","Epoch 26/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2765 - val_loss: 0.2946\n","Epoch 27/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2738 - val_loss: 0.2955\n","Epoch 28/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2724 - val_loss: 0.2772\n","Epoch 29/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2724 - val_loss: 0.2876\n","Epoch 30/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2702 - val_loss: 0.2959\n","Epoch 31/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2691 - val_loss: 0.3144\n","Epoch 32/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2684 - val_loss: 0.2710\n","Epoch 33/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2653 - val_loss: 0.2724\n","Epoch 34/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2656 - val_loss: 0.2716\n","Epoch 35/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2631 - val_loss: 0.2901\n","Epoch 36/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2622 - val_loss: 0.2961\n","Epoch 37/50\n","363/363 [==============================] - 1s 2ms/step - loss: 0.2621 - val_loss: 0.2948\n","Epoch 38/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2626 - val_loss: 0.3307\n","Epoch 39/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2588 - val_loss: 0.4664\n","Epoch 40/50\n","363/363 [==============================] - 2s 5ms/step - loss: 0.2586 - val_loss: 0.2672\n","Epoch 41/50\n","363/363 [==============================] - 3s 8ms/step - loss: 0.2589 - val_loss: 0.2994\n","Epoch 42/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2564 - val_loss: 0.2651\n","Epoch 43/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2573 - val_loss: 0.2674\n","Epoch 44/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2553 - val_loss: 0.2696\n","Epoch 45/50\n","363/363 [==============================] - 1s 3ms/step - loss: 0.2556 - val_loss: 0.2765\n","Epoch 46/50\n","363/363 [==============================] - 2s 4ms/step - loss: 0.2534 - val_loss: 0.2554\n","Epoch 47/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2516 - val_loss: 0.3033\n","Epoch 48/50\n","363/363 [==============================] - 1s 4ms/step - loss: 0.2521 - val_loss: 0.2661\n","Epoch 49/50\n","363/363 [==============================] - 2s 5ms/step - loss: 0.2515 - val_loss: 0.2771\n","Epoch 50/50\n","363/363 [==============================] - 3s 8ms/step - loss: 0.2514 - val_loss: 0.2577\n","121/121 [==============================] - 0s 2ms/step\n","0.5076683354576565\n"]}],"source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import SGD\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import fetch_california_housing\n","\n","# Load the California housing dataset\n","housing = fetch_california_housing()\n","\n","# Split the dataset into training and testing sets\n","X_train_full, X_test, y_train_full, y_test = train_test_split(\n","    housing.data, housing.target, random_state=42)\n","\n","# Further split the training set into training and validation sets\n","X_train, X_valid, y_train, y_valid = train_test_split(\n","    X_train_full, y_train_full, random_state=42)\n","\n","# Standardize the features using StandardScaler\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_valid_scaled = scaler.transform(X_valid)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Create a Keras Sequential model\n","model = Sequential([\n","    Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n","    Dense(100, activation='relu'),\n","    Dense(100, activation='relu'),\n","    Dense(1)  # Output layer with a single neuron for regression\n","])\n","\n","# Compile the model\n","model.compile(optimizer=SGD(learning_rate=0.01), loss='mean_squared_error')\n","\n","# Train the model on the training data\n","model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_valid_scaled, y_valid), verbose=1)\n","\n","# Make predictions on the validation set\n","y_pred = model.predict(X_valid_scaled).flatten()\n","\n","# Calculate the Root Mean Squared Error (RMSE) between the predicted and actual values\n","rmse = mean_squared_error(y_valid, y_pred, squared=False)\n","\n","# Display the RMSE as the result\n","print(rmse)\n"]}]}